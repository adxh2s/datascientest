# model learning regression lineaire
from sklearn import svm, preprocessing, model_selection, neighbors, datasets 
from sklearn.model_selection import train_test_split 
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

# Pandas et Numpy pour dataframe et calcul
import pandas as pd
import numpy as np

import matplotlib.pyplot as plt
from matplotlib import cm

from IPython.display import display

import warnings

warnings.filterwarnings("ignore")

# Configuration pour un affichage plus riche
pd.set_option("display.max_columns", None)
pd.set_option("display.max_rows", 50)
pd.set_option("display.width", None)
pd.set_option("display.max_colwidth", 50)


def display_dataframe_info(df, title="DataFrame Info"):
    """Affiche les informations du DataFrame de mani√®re format√©e"""
    print("=" * 80)
    print(f"üìä {title}")
    print("=" * 80)

    # Informations de base
    print(
        f"üìã Forme du DataFrame: {df.shape[0]} lignes √ó {df.shape[1]} colonnes"
    )
    print(
        f"üíæ Utilisation m√©moire: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB"
    )
    print()

    # Types de donn√©es
    print("üîç Types de donn√©es:")
    print("-" * 40)
    for col, dtype in df.dtypes.items():
        print(f"  {col:<25} | {dtype}")
    print()

    # Valeurs manquantes
    missing_values = df.isnull().sum()
    if missing_values.sum() > 0:
        print("‚ùå Valeurs manquantes:")
        print("-" * 40)
        for col, missing in missing_values.items():
            if missing > 0:
                percentage = (missing / len(df)) * 100
                print(f"  {col:<25} | {missing:>6} ({percentage:>5.1f}%)")
        print()
    else:
        print("‚úÖ Aucune valeur manquante d√©tect√©e")
        print()

    # Aper√ßu des donn√©es
    print("üëÄ Aper√ßu des donn√©es (5 premi√®res lignes):")
    print("-" * 40)
    print(df.head().to_string())
    print()

    # Statistiques descriptives pour les colonnes num√©riques
    numeric_cols = df.select_dtypes(include=[np.number]).columns
    if len(numeric_cols) > 0:
        print("üìà Statistiques descriptives (colonnes num√©riques):")
        print("-" * 40)
        print(df[numeric_cols].describe().to_string())
        print()

    # Valeurs uniques pour les colonnes cat√©gorielles (limit√©es)
    categorical_cols = df.select_dtypes(include=["object"]).columns
    if len(categorical_cols) > 0:
        print("üè∑Ô∏è  Aper√ßu des valeurs uniques (colonnes cat√©gorielles):")
        print("-" * 40)
        for col in categorical_cols[
            :5
        ]:  # Limite √† 5 colonnes pour √©viter l'encombrement
            unique_count = df[col].nunique()
            print(f"  {col}: {unique_count} valeurs uniques")
            if unique_count <= 10:
                print(f"    Valeurs: {list(df[col].unique())}")
            else:
                print(f"    Exemples: {list(df[col].unique()[:5])}...")
        print()


# Fonction pour afficher des informations sp√©cifiques sur les colonnes
def explore_column(df, column_name):
    """Explore une colonne sp√©cifique du DataFrame"""
    if column_name not in df.columns:
        print(f"‚ùå La colonne '{column_name}' n'existe pas.")
        return

    print(f"\nüîç Exploration de la colonne: {column_name}")
    print("-" * 50)
    print(f"Type: {df[column_name].dtype}")
    print(f"Valeurs uniques: {df[column_name].nunique()}")
    print(f"Valeurs manquantes: {df[column_name].isnull().sum()}")

    if df[column_name].dtype == "object":
        print("\nValeurs les plus fr√©quentes:")
        print(df[column_name].value_counts().head(10))
    elif df[column_name].dtype in ["int64", "float64"]:
        print(f"\nMin: {df[column_name].min()}")
        print(f"Max: {df[column_name].max()}")
        print(f"Moyenne: {df[column_name].mean():.2f}")
        print(f"M√©diane: {df[column_name].median():.2f}")
        
        
# chargement donnn√©es dans un dictionnaire
# On utilise le dataset digits de sklearn pour la classification
dict_df = datasets.load_digits()
for key, value in enumerate(dict_df):
    print("key : ", key)
# S√©lection des donn√©es et de la cible
X = pd.DataFrame(dict_df['data'])
y = dict_df['target']

# Informations du dataframe
display_dataframe_info(X, title="Aper√ßu des donn√©es X")

# affichage 
j=0

for i in np.random.choice(np.arange(0, len(y)), size=6):
    j=j+1
#On stocke l'indice dans la liste i pour pouvoir afficher le label correspondant plus tard.
    
    plt.subplot(2,3,j)
# Rajouter *plt.subplot(2,3,j)* √† chaque it√©ration permet d'afficher toutes les images
# ensembles sur la m√™me figure.

    plt.axis('off')
# Permet de supprimer les axes (ici sert √† mieux voir les titres)
    
    plt.imshow(dict_df.images[i], cmap = cm.binary, interpolation='None')
# Affiche l'image n¬∞i
# L'utilisation de cm.binary permet de voir les chiffres en gris sur fond blanc.

    plt.title('Label: %i' %y[i])
# Pour chaque image on √©crit en titre le label qui lui correspond

plt.show()

# D√©composition des donn√©es en deux ensembles d'entra√Ænement et de test
# par d√©faut l'√©chantillon est al√©atoirement r√©parti
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=126)

# help(neighbors.KNeighborsClassifier)
# choix du mod√®le
knn = neighbors.KNeighborsClassifier(n_neighbors=7, metric='minkowski', p=2)
# Ajustement du mod√®le aux donn√©es d'entra√Ænement
knn.fit(X_train, y_train)

# Pr√©diction sur les donn√©es de test
# On utilise la m√©thode predict() pour pr√©dire les classes des donn√©es de test
y_pred = knn.predict(X=X_test)
# Affichage de la matrice de confusion
cm = confusion_matrix(y_test, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=knn.classes_)
disp.plot(cmap=plt.cm.Blues)
# Affichage de la matrice de confusion
plt.title("Matrice de confusion")
plt.show()
# ou via pandas
cm2 = pd.crosstab(y_test, y_pred, rownames=['Classe r√©elle'], colnames=['Classe pr√©dite'])
print(cm2)

# Cr√©ation du classifieur et construction du mod√®le sur les donn√©es d'entra√Ænement
knn_m = neighbors.KNeighborsClassifier(n_neighbors=5, metric='manhattan')
knn_m.fit(X_train, y_train)
# Score des 2 mod√®les
print(knn.score(X_test, y_test))
print(knn_m.score(X_test, y_test))

# Comparaison des scores pour diff√©rentes m√©triques et valeurs de k voisins
score_minko = []
score_man = []
score_cheb = []

for k in range(1, 41):
    knn = neighbors.KNeighborsClassifier(n_neighbors=k)
    knn.fit(X_train, y_train)
    score_minko.append(knn.score(X_test, y_test))

for k in range(1, 41):
    knn = neighbors.KNeighborsClassifier(n_neighbors=k, metric='manhattan')
    knn.fit(X_train, y_train)
    score_man.append(knn.score(X_test, y_test))
    
for k in range(1, 41):
    knn = neighbors.KNeighborsClassifier(n_neighbors=k, metric='chebyshev')
    knn.fit(X_train, y_train)
    score_cheb.append(knn.score(X_test, y_test))
    
# Affichage des scores pour chaque m√©trique
plt.figure(figsize=(12, 6))    
plt.grid(visible=True)
plt.plot(range(1,41), score_minko, 'r', label='min')
plt.plot(range(1,41), score_man, 'b', label='man')
plt.plot(range(1,41), score_cheb, 'y', label='cheb')
plt.legend(loc='best')
plt.xlabel('k')
plt.ylabel('score')
plt.show()