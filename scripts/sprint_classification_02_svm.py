# model learning regression lineaire
from sklearn import linear_model, preprocessing 
from sklearn.model_selection import train_test_split, GridSearchCV, learning_curve
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
# Pour l'encodage des variables cat√©gorielles
from sklearn.preprocessing import OneHotEncoder

# Pandas et Numpy pour dataframe et calcul
import pandas as pd
import numpy as np

import matplotlib.pyplot as plt

from IPython.display import display

import warnings

warnings.filterwarnings("ignore")

# Configuration pour un affichage plus riche
pd.set_option("display.max_columns", None)
pd.set_option("display.max_rows", 50)
pd.set_option("display.width", None)
pd.set_option("display.max_colwidth", 50)


def display_dataframe_info(df, title="DataFrame Info"):
    """Affiche les informations du DataFrame de mani√®re format√©e"""
    print("=" * 80)
    print(f"üìä {title}")
    print("=" * 80)

    # Informations de base
    print(
        f"üìã Forme du DataFrame: {df.shape[0]} lignes √ó {df.shape[1]} colonnes"
    )
    print(
        f"üíæ Utilisation m√©moire: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB"
    )
    print()

    # Types de donn√©es
    print("üîç Types de donn√©es:")
    print("-" * 40)
    for col, dtype in df.dtypes.items():
        print(f"  {col:<25} | {dtype}")
    print()

    # Valeurs manquantes
    missing_values = df.isnull().sum()
    if missing_values.sum() > 0:
        print("‚ùå Valeurs manquantes:")
        print("-" * 40)
        for col, missing in missing_values.items():
            if missing > 0:
                percentage = (missing / len(df)) * 100
                print(f"  {col:<25} | {missing:>6} ({percentage:>5.1f}%)")
        print()
    else:
        print("‚úÖ Aucune valeur manquante d√©tect√©e")
        print()

    # Aper√ßu des donn√©es
    print("üëÄ Aper√ßu des donn√©es (5 premi√®res lignes):")
    print("-" * 40)
    print(df.head().to_string())
    print()

    # Statistiques descriptives pour les colonnes num√©riques
    numeric_cols = df.select_dtypes(include=[np.number]).columns
    if len(numeric_cols) > 0:
        print("üìà Statistiques descriptives (colonnes num√©riques):")
        print("-" * 40)
        print(df[numeric_cols].describe().to_string())
        print()

    # Valeurs uniques pour les colonnes cat√©gorielles (limit√©es)
    categorical_cols = df.select_dtypes(include=["object"]).columns
    if len(categorical_cols) > 0:
        print("üè∑Ô∏è  Aper√ßu des valeurs uniques (colonnes cat√©gorielles):")
        print("-" * 40)
        for col in categorical_cols[
            :5
        ]:  # Limite √† 5 colonnes pour √©viter l'encombrement
            unique_count = df[col].nunique()
            print(f"  {col}: {unique_count} valeurs uniques")
            if unique_count <= 10:
                print(f"    Valeurs: {list(df[col].unique())}")
            else:
                print(f"    Exemples: {list(df[col].unique()[:5])}...")
        print()


# Fonction pour afficher des informations sp√©cifiques sur les colonnes
def explore_column(df, column_name):
    """Explore une colonne sp√©cifique du DataFrame"""
    if column_name not in df.columns:
        print(f"‚ùå La colonne '{column_name}' n'existe pas.")
        return

    print(f"\nüîç Exploration de la colonne: {column_name}")
    print("-" * 50)
    print(f"Type: {df[column_name].dtype}")
    print(f"Valeurs uniques: {df[column_name].nunique()}")
    print(f"Valeurs manquantes: {df[column_name].isnull().sum()}")

    if df[column_name].dtype == "object":
        print("\nValeurs les plus fr√©quentes:")
        print(df[column_name].value_counts().head(10))
    elif df[column_name].dtype in ["int64", "float64"]:
        print(f"\nMin: {df[column_name].min()}")
        print(f"Max: {df[column_name].max()}")
        print(f"Moyenne: {df[column_name].mean():.2f}")
        print(f"M√©diane: {df[column_name].median():.2f}")
        
        
# chargement donnn√©es
df = pd.read_csv('../data/winequality-red.csv') #, index_col=0)

# Informations du dataframe
display_dataframe_info(df)

# Remplacer les espaces par des underscores dans les noms de colonnes
df.columns = [col.replace(' ', '_') for col in df.columns]
    
# separation des donn√©es et de la cible
# On suppose que la colonne 'quality' est la cible
data = df.drop(columns='quality', axis=1)
target = df['quality']

# S√©paration des donn√©es en ensembles d'entra√Ænement et de test
X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=66)

# Standardisation des donn√©es d'entra√Ænement
X_train_scaled = preprocessing.scale(X_train)

# Moyenne et √©cart-type des donn√©es d'entra√Ænement
print(X_train_scaled.mean(axis=0))
print(X_train_scaled.std(axis=0))

scaler = preprocessing.StandardScaler().fit(X_train)
X_train_scaled = scaler.transform(X_train)

print(X_train_scaled.mean(axis=0))
print(X_train_scaled.std(axis=0))

# Standardisation des donn√©es de test
X_test_scaled = scaler.transform(X_test)

print(X_test_scaled.mean(axis=0))
print(X_test_scaled.std(axis=0))

# Instanciation de la classe SVM avec un noyau polynomial
from sklearn import svm
clf = svm.SVC(gamma=0.01, kernel='poly')
# Entra√Ænement du mod√®le SVM
# On utilise les donn√©es d'entra√Ænement standardis√©es
clf.fit(X_train_scaled, y_train)

# Pr√©diction sur les donn√©es de test
# On utilise les donn√©es de test standardis√©es
y_pred = clf.predict(X_test_scaled)

# Methode 1 : Affichage de la matrice de confusion
cm = confusion_matrix(y_test, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=clf.classes_)
disp.plot(cmap=plt.cm.Blues)
plt.title("Matrice de confusion")
plt.show()
# M√©thode 2 : Affichage de la matrice de confusion avec pandas
cm2 = pd.crosstab(y_test, y_pred, rownames=['Classe r√©elle'], colnames=['Classe pr√©dite'])
print(cm2)

# On va passer par une grille de mod√®les pour √©valuer les parametres
parametres = {
    'C': [0.1, 1, 10],
    'kernel': ['rbf', 'linear', 'poly'],
    'gamma': [0.001, 0.1, 0.5],
}
# Instanciation de la grille de recherche
grid_clf = GridSearchCV(estimator=clf, param_grid=parametres)
# Entra√Ænement de la grille de recherche
# On utilise les donn√©es d'entra√Ænement standardis√©es
grille = grid_clf.fit(X_train_scaled, y_train)
# Affichage des r√©sultats de la grille de recherche
print("Meilleurs param√®tres trouv√©s:")
print(pd.DataFrame.from_dict(grille.cv_results_).loc[:,['params', 'mean_test_score']]) 

# Affichage des meilleurs param√®tres
print("Meilleurs param√®tres:")
print(grid_clf.best_params_)

# Pr√©diction avec les meilleurs param√®tres
# On utilise les donn√©es de test standardis√©es
y_pred = grid_clf.predict(X_test_scaled)
# Affichage de la matrice de confusion avec les meilleurs param√®tres
cm3 = pd.crosstab(y_test, y_pred, rownames=['Classe r√©elle'], colnames=['Classe pr√©dite'])
print(cm3)

# Comparaison du score du mod√®le avec les meilleurs param√®tres
linear_train_sizes = [50, 70, 80, 100, 110, 118]
linear_train_sizes, linear_train_scores, linear_valid_scores = learning_curve(svm.SVC(kernel='linear', C= 1), data, target, train_sizes=linear_train_sizes, cv=5)

# Partie linear
train_scores_mean = np.mean(linear_train_scores, axis=1)
train_scores_std = np.std(linear_train_scores, axis=1)
valid_scores_mean = np.mean(linear_valid_scores, axis=1)
valid_scores_std = np.std(linear_valid_scores, axis=1)

# figure pour la courbe d'apprentissage
fig = plt.figure(figsize=(10, 10))
axis = fig.add_subplot(121)
# Grille
axis.grid()

# Halo autour de la courbe (bandes d'√©cart-type)
axis.fill_between(linear_train_sizes, train_scores_mean - train_scores_std,
                train_scores_mean + train_scores_std, alpha=0.1, color="r")
axis.fill_between(linear_train_sizes, valid_scores_mean - valid_scores_std,
                valid_scores_mean + valid_scores_std, alpha=0.1, color="g")

# Courbes
axis.plot(linear_train_sizes, train_scores_mean, 'o-', color="r", label="Training score")
axis.plot(linear_train_sizes, valid_scores_mean, 'o-', color="g", label="Cross-validation score")

# L√©gende et titre
axis.legend(loc="best")
axis.set_title("Courbe d'apprentissage svm linear")
axis.set_xlabel("Training examples")
axis.set_ylabel("Score")


# Affichage de la courbe d'apprentissage
grid_train_sizes = [50, 70, 80, 100, 110, 118]
grid_train_sizes, grid_train_scores, grid_test_scores = learning_curve(grid_clf, data, target, n_jobs=4, train_sizes=grid_train_sizes)

# Partie grid
train_scores_mean = np.mean(grid_train_scores, axis=1)
train_scores_std = np.std(grid_train_scores, axis=1)
test_scores_mean = np.mean(grid_test_scores, axis=1)
test_scores_std = np.std(grid_test_scores, axis=1)

# figure pour la courbe d'apprentissage
axis = fig.add_subplot(122)
# Grille
axis.grid()
# Halo autour des courbes (bandes d‚Äôincertitude)
axis.fill_between(grid_train_sizes, train_scores_mean - train_scores_std,
                train_scores_mean + train_scores_std, alpha=0.1, color="r")
axis.fill_between(grid_train_sizes, test_scores_mean - test_scores_std,
                test_scores_mean + test_scores_std, alpha=0.1, color="g")

# Courbes des scores moyens d‚Äôentra√Ænement et de validation crois√©e
axis.plot(grid_train_sizes, train_scores_mean, 'o-', color="r", label="Training score")
axis.plot(grid_train_sizes, test_scores_mean, 'o-', color="g", label="Cross-validation score")

# L√©gende, titre et labels des axes
axis.legend(loc="best")
axis.set_title("Courbe d'apprentissage svm avec grille de recherche")
axis.set_xlabel("Training examples")
axis.set_ylabel("Score")

plt.show()