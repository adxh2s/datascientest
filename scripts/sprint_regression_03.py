import numpy as np
import pandas as pd

from sklearn import preprocessing
from sklearn.model_selection import train_test_split, cross_val_score, cross_validate
from sklearn.metrics import mean_squared_error

import matplotlib.pyplot as plt

import scipy.stats as stats
import seaborn as sns

from IPython.display import display

import warnings

warnings.filterwarnings("ignore")


# Configuration pour un affichage plus riche
pd.set_option("display.max_columns", None)
pd.set_option("display.max_rows", 50)
pd.set_option("display.width", None)
pd.set_option("display.max_colwidth", 50)


def display_dataframe_info(df, title="DataFrame Info"):
    """Affiche les informations du DataFrame de mani√®re format√©e"""
    print("=" * 80)
    print(f"üìä {title}")
    print("=" * 80)

    # Informations de base
    print(
        f"üìã Forme du DataFrame: {df.shape[0]} lignes √ó {df.shape[1]} colonnes"
    )
    print(
        f"üíæ Utilisation m√©moire: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB"
    )
    print()

    # Types de donn√©es
    print("üîç Types de donn√©es:")
    print("-" * 40)
    for col, dtype in df.dtypes.items():
        print(f"  {col:<25} | {dtype}")
    print()

    # Valeurs manquantes
    missing_values = df.isnull().sum()
    if missing_values.sum() > 0:
        print("‚ùå Valeurs manquantes:")
        print("-" * 40)
        for col, missing in missing_values.items():
            if missing > 0:
                percentage = (missing / len(df)) * 100
                print(f"  {col:<25} | {missing:>6} ({percentage:>5.1f}%)")
        print()
    else:
        print("‚úÖ Aucune valeur manquante d√©tect√©e")
        print()

    # Aper√ßu des donn√©es
    print("üëÄ Aper√ßu des donn√©es (5 premi√®res lignes):")
    print("-" * 40)
    print(df.head().to_string())
    print()

    # Statistiques descriptives pour les colonnes num√©riques
    numeric_cols = df.select_dtypes(include=[np.number]).columns
    if len(numeric_cols) > 0:
        print("üìà Statistiques descriptives (colonnes num√©riques):")
        print("-" * 40)
        print(df[numeric_cols].describe().to_string())
        print()

    # Valeurs uniques pour les colonnes cat√©gorielles (limit√©es)
    categorical_cols = df.select_dtypes(include=["object"]).columns
    if len(categorical_cols) > 0:
        print("üè∑Ô∏è  Aper√ßu des valeurs uniques (colonnes cat√©gorielles):")
        print("-" * 40)
        for col in categorical_cols[
            :5
        ]:  # Limite √† 5 colonnes pour √©viter l'encombrement
            unique_count = df[col].nunique()
            print(f"  {col}: {unique_count} valeurs uniques")
            if unique_count <= 10:
                print(f"    Valeurs: {list(df[col].unique())}")
            else:
                print(f"    Exemples: {list(df[col].unique()[:5])}...")
        print()


# Fonction pour afficher des informations sp√©cifiques sur les colonnes
def explore_column(df, column_name):
    """Explore une colonne sp√©cifique du DataFrame"""
    if column_name not in df.columns:
        print(f"‚ùå La colonne '{column_name}' n'existe pas.")
        return

    print(f"\nüîç Exploration de la colonne: {column_name}")
    print("-" * 50)
    print(f"Type: {df[column_name].dtype}")
    print(f"Valeurs uniques: {df[column_name].nunique()}")
    print(f"Valeurs manquantes: {df[column_name].isnull().sum()}")

    if df[column_name].dtype == "object":
        print("\nValeurs les plus fr√©quentes:")
        print(df[column_name].value_counts().head(10))
    elif df[column_name].dtype in ["int64", "float64"]:
        print(f"\nMin: {df[column_name].min()}")
        print(f"Max: {df[column_name].max()}")
        print(f"Moyenne: {df[column_name].mean():.2f}")
        print(f"M√©diane: {df[column_name].median():.2f}")


# Charger le dataset
df = pd.read_csv("../data/CarPrice_Assignment.csv", index_col=0)

# Afficher les informations du DataFrame
display_dataframe_info(df)

# Visualiser la relation entre 'curb-weight' et 'price'
df.rename(columns={"curbweight": "curb-weight"}, inplace=True)
# Afficher des informations sp√©cifiques sur certaines colonnes
explore_column(df, "curb-weight")
explore_column(df, "price")

# Visualisation de la relation entre 'curb-weight' et 'price'
# plt.style.use('seaborn-darkgrid')
# fig = plt.figure(figsize=(5, 5))
# ax = fig.add_subplot(111)
# ax.scatter(x=df['curb-weight'], y=df['price'])
# sns.relplot(x=df['curb-weight'], y=df['price'])
# plt.show()

# S√©lectionner les colonnes pour X (data) et y (target)
# X = df[['curb-weight']] # renvoie un DataFrame pandas, equivalent √† X = pd.DataFrame(df['curb-weight'])
# y = df['price'] # renvoie une s√©rie pandas
# display(df[['CarName', 'fueltype', 'aspiration', 'doornumber', 'carbody',
#             'drivewheel', 'enginelocation', 'enginetype', 'cylindernumber',
#             'fuelsystem']].head())
X = df.drop(
    columns=[
        "CarName",
        "fueltype",
        "aspiration",
        "doornumber",
        "carbody",
        "drivewheel",
        "enginelocation",
        "enginetype",
        "cylindernumber",
        "fuelsystem",
        "price",
    ],
    axis="1",
)
y = df["price"]

# S√©paration des donn√©es d'entrainement et de test
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=789
)

# standardisation des donn√©es
# V1 tranformation directe (uniquement sur de l'exploration)
# scaler = preprocessing.StandardScaler()
# X_train[X_train.columns] = pd.DataFrame(scaler.fit_transform(X_train), index=X_train.index)
# X_test[X_test.columns] = pd.DataFrame(scaler.transform(X_test), index=X_test.index)
# ------------------------------------------
# V2 standardisation des donn√©es


# version propre pour la prod
def scale_dataframe(scaler, df):
    return pd.DataFrame(
        scaler.transform(df),
        columns=df.columns,
        index=df.index
    )


# Standardisation des donn√©es
# Cr√©er un scaler et l'ajuster sur les donn√©es d'entra√Ænement
scaler = preprocessing.StandardScaler()
scaler.fit(X_train)
# Appliquer la transformation sur les donn√©es d'entra√Ænement et de test
X_train_scaled = scale_dataframe(scaler, X_train)
X_test_scaled = scale_dataframe(scaler, X_test)

# Ridge Regression avec validation crois√©e
from sklearn.linear_model import RidgeCV

# instanciation d'un RidgeCV
rcv = RidgeCV(alphas=(0.001, 0.01, 0.1, 0.3, 0.7, 1, 10, 50, 100))
# Entra√Ænement sur les donn√©es d'apprentissage standardis√©es
rcv.fit(X_train_scaled, y_train)

# alpha retenu
print('alpha s√©lectionn√© par c-v :', rcv.alpha_)

# score R¬≤ entra√Ænement et test
print( "R¬≤ - Coefficient de d√©termination du mod√®le ridge sur train     :", rcv.score(X_train_scaled, y_train))
print( "R¬≤ - Coefficient de d√©termination du mod√®le ridge sur test      :", rcv.score(X_test_scaled, y_test))

# Valeurs ajust√©es du mod√®le ou pr√©dictions
rcv_pred_train = rcv.predict(X_train_scaled)
rcv_pred_test = rcv.predict(X_test_scaled)

# affichage MSE
print('MSE - Erreur quadratique moyenne de pr√©diction sur train: ', mean_squared_error(rcv_pred_train, y_train))
print('MSE - Erreur quadratique moyenne de pr√©diction sur test : ', mean_squared_error(rcv_pred_test, y_test))

# Mod√®le Lasso
from sklearn.linear_model import Lasso

# Entra√Ænement du mod√®le Lasso avec alpha=1
lasso_r = Lasso(alpha=1)
lasso_r.fit(X_train_scaled, y_train)

# Affichage des coefficients
print("Coefficients de la r√©gression lin√©aire simple :")
print("ordonn√©e √† l'origine : ", lasso_r.intercept_)
for index, coef in enumerate(lasso_r.coef_):
    print("variable", lasso_r.feature_names_in_[index], "- pente ou coefficient estim√© : ", coef)
    
# OU Extraire les coefficients et l'intercept
coeffs = list(lasso_r.coef_)
coeffs.insert(0, lasso_r.intercept_)
# Ajouter le nom de l'intercept et les noms des colonnes
feats = list(X.columns)
feats.insert(0, "intercept")
# Afficher les coefficients dans un DataFrame
display(pd.DataFrame({"valeur estim√©e": coeffs}, index=feats))

# Entra√Ænement du mod√®le Lasso avec alpha=10
lasso_r2 = Lasso(alpha=10)
lasso_r2.fit(X_train_scaled, y_train)
# Affichage des coefficients
plt.plot(range(len(X.columns)), lasso_r2.coef_)
plt.xticks(range(len(X.columns)), X.columns.values, rotation=70)
plt.xlabel('Variables')
plt.ylabel('Coefficients')
plt.title('Coefficients du mod√®le Lasso avec alpha=10')
plt.grid()
plt.show()

# score R¬≤ entra√Ænement et test
print( "R¬≤ - Coefficient de d√©termination du mod√®le Lasso alpha 10 sur train: ", lasso_r2.score(X_train_scaled, y_train))
print( "R¬≤ - Coefficient de d√©termination du mod√®le Lasso alpha 10 sur test : ", lasso_r2.score(X_test_scaled, y_test))

# Valeurs ajust√©es du mod√®le ou pr√©dictions
lasso_r2_pred_train = lasso_r2.predict(X_train_scaled)
lasso_r2_pred_test = lasso_r2.predict(X_test_scaled)

# affichage MSE
print('MSE - Erreur quadratique moyenne de pr√©diction Lasso alpha 10 sur train: ', mean_squared_error(lasso_r2_pred_train, y_train))
print('MSE - Erreur quadratique moyenne de pr√©diction Lasso alpha 10 sur test : ', mean_squared_error(lasso_r2_pred_test, y_test))

# Lasso avec validation crois√©e pour trouver le meilleur alpha
from sklearn.linear_model import LassoCV

# Entra√Ænement du mod√®le Lasso avec validation crois√©e
lcv = LassoCV(cv=10)
lcv.fit(X_train_scaled, y_train)
print('Valeur alpha optimale :', lcv.alpha_)

# Affichage des coefficients
plt.figure(figsize=(10, 8))
plt.plot(lcv.alphas_, lcv.mse_path_, ':')
plt.plot(lcv.alphas_, lcv.mse_path_.mean(axis=1), 'k', label='moyenne des MSE')
plt.axvline(lcv.alpha_, linestyle='--', color='k', label='alpha : estimation CV')
plt.legend()
plt.xlabel('Alpha')
plt.ylabel('Mean square error')
plt.title('Mean square error pour chaque √©chantillon')
plt.show()

# affichage R¬≤
print('score train lcv :', lcv.score(X_train_scaled, y_train))
print('score test lcv  :', lcv.score(X_test_scaled, y_test))

# Valeurs ajust√©es du mod√®le ou pr√©dictions
lcv_pred_train = lcv.predict(X_train_scaled)
lcv_pred_test = lcv.predict(X_test_scaled)

# affichage MSE
print('Erreur quadratique moyenne de pr√©diction lcv sur train: ', mean_squared_error(lcv_pred_train, y_train))
print('Erreur quadratique moyenne de pr√©diction lcv sur test : ', mean_squared_error(lcv_pred_test, y_test))
