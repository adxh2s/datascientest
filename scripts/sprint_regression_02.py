import numpy as np
import pandas as pd

from sklearn import model_selection, preprocessing
from sklearn.model_selection import (
    cross_val_predict,
    cross_val_score,
    cross_validate,
)
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split

import matplotlib.pyplot as plt

import scipy.stats as stats
import seaborn as sns

from IPython.display import display

import warnings

warnings.filterwarnings("ignore")


# Configuration pour un affichage plus riche
pd.set_option("display.max_columns", None)
pd.set_option("display.max_rows", 50)
pd.set_option("display.width", None)
pd.set_option("display.max_colwidth", 50)


def display_dataframe_info(df, title="DataFrame Info"):
    """Affiche les informations du DataFrame de mani√®re format√©e"""
    print("=" * 80)
    print(f"üìä {title}")
    print("=" * 80)

    # Informations de base
    print(
        f"üìã Forme du DataFrame: {df.shape[0]} lignes √ó {df.shape[1]} colonnes"
    )
    print(
        f"üíæ Utilisation m√©moire: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB"
    )
    print()

    # Types de donn√©es
    print("üîç Types de donn√©es:")
    print("-" * 40)
    for col, dtype in df.dtypes.items():
        print(f"  {col:<25} | {dtype}")
    print()

    # Valeurs manquantes
    missing_values = df.isnull().sum()
    if missing_values.sum() > 0:
        print("‚ùå Valeurs manquantes:")
        print("-" * 40)
        for col, missing in missing_values.items():
            if missing > 0:
                percentage = (missing / len(df)) * 100
                print(f"  {col:<25} | {missing:>6} ({percentage:>5.1f}%)")
        print()
    else:
        print("‚úÖ Aucune valeur manquante d√©tect√©e")
        print()

    # Aper√ßu des donn√©es
    print("üëÄ Aper√ßu des donn√©es (5 premi√®res lignes):")
    print("-" * 40)
    print(df.head().to_string())
    print()

    # Statistiques descriptives pour les colonnes num√©riques
    numeric_cols = df.select_dtypes(include=[np.number]).columns
    if len(numeric_cols) > 0:
        print("üìà Statistiques descriptives (colonnes num√©riques):")
        print("-" * 40)
        print(df[numeric_cols].describe().to_string())
        print()

    # Valeurs uniques pour les colonnes cat√©gorielles (limit√©es)
    categorical_cols = df.select_dtypes(include=["object"]).columns
    if len(categorical_cols) > 0:
        print("üè∑Ô∏è  Aper√ßu des valeurs uniques (colonnes cat√©gorielles):")
        print("-" * 40)
        for col in categorical_cols[
            :5
        ]:  # Limite √† 5 colonnes pour √©viter l'encombrement
            unique_count = df[col].nunique()
            print(f"  {col}: {unique_count} valeurs uniques")
            if unique_count <= 10:
                print(f"    Valeurs: {list(df[col].unique())}")
            else:
                print(f"    Exemples: {list(df[col].unique()[:5])}...")
        print()


# Fonction pour afficher des informations sp√©cifiques sur les colonnes
def explore_column(df, column_name):
    """Explore une colonne sp√©cifique du DataFrame"""
    if column_name not in df.columns:
        print(f"‚ùå La colonne '{column_name}' n'existe pas.")
        return

    print(f"\nüîç Exploration de la colonne: {column_name}")
    print("-" * 50)
    print(f"Type: {df[column_name].dtype}")
    print(f"Valeurs uniques: {df[column_name].nunique()}")
    print(f"Valeurs manquantes: {df[column_name].isnull().sum()}")

    if df[column_name].dtype == "object":
        print("\nValeurs les plus fr√©quentes:")
        print(df[column_name].value_counts().head(10))
    elif df[column_name].dtype in ["int64", "float64"]:
        print(f"\nMin: {df[column_name].min()}")
        print(f"Max: {df[column_name].max()}")
        print(f"Moyenne: {df[column_name].mean():.2f}")
        print(f"M√©diane: {df[column_name].median():.2f}")


# Charger le dataset
df = pd.read_csv("../data/CarPrice_Assignment.csv", index_col=0)

# Afficher les informations du DataFrame
display_dataframe_info(df)

# Visualiser la relation entre 'curb-weight' et 'price'
df.rename(columns={"curbweight": "curb-weight"}, inplace=True)
# Afficher des informations sp√©cifiques sur certaines colonnes
explore_column(df, "curb-weight")
explore_column(df, "price")

# Visualisation de la relation entre 'curb-weight' et 'price'
# plt.style.use('seaborn-darkgrid')
# fig = plt.figure(figsize=(5, 5))
# ax = fig.add_subplot(111)
# ax.scatter(x=df['curb-weight'], y=df['price'])
# sns.relplot(x=df['curb-weight'], y=df['price'])
# plt.show()

# S√©lectionner les colonnes pour X (data) et y (target)
# X = df[['curb-weight']] # renvoie un DataFrame pandas, equivalent √† X = pd.DataFrame(df['curb-weight'])
# y = df['price'] # renvoie une s√©rie pandas
# display(df[['CarName', 'fueltype', 'aspiration', 'doornumber', 'carbody',
#             'drivewheel', 'enginelocation', 'enginetype', 'cylindernumber',
#             'fuelsystem']].head())
X = df.drop(
    columns=[
        "CarName",
        "fueltype",
        "aspiration",
        "doornumber",
        "carbody",
        "drivewheel",
        "enginelocation",
        "enginetype",
        "cylindernumber",
        "fuelsystem",
        "price",
    ],
    axis="1",
)
y = df["price"]

# S√©paration des donn√©es d'entrainement et de test
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=789
)

# # standardisation des donn√©es
# scaler = preprocessing.StandardScaler()
# X_train[X_train.columns] = pd.DataFrame(scaler.fit_transform(X_train), index=X_train.index)
# X_test[X_test.columns] = pd.DataFrame(scaler.transform(X_test), index=X_test.index)

# Ins√©rez votre code ici
slr = LinearRegression()

# Entrainement
slr.fit(X_train, y_train)

# Affichage des coefficients
print("Coefficients de la r√©gression lin√©aire simple :")
# Extraire les coefficients et l'intercept
coeffs = list(slr.coef_)
coeffs.insert(0, slr.intercept_)
# Ajouter le nom de l'intercept et les noms des colonnes
feats = list(X.columns)
feats.insert(0, "intercept")
# Afficher les coefficients dans un DataFrame
display(pd.DataFrame({"valeur estim√©e": coeffs}, index=feats))

# Metriques R¬≤
print(
    "Coefficient de d√©termination du mod√®le sur train     :",
    slr.score(X_train, y_train),
)
print(
    "Coefficient de d√©termination obtenu par Cv sur train :",
    cross_val_score(slr, X_train, y_train).mean(),
)
print(
    "Coefficient de d√©termination du mod√®le sur test      :",
    slr.score(X_test, y_test),
)

# pr√©diction √† partir de l'environnement test
y_pred_test = slr.predict(X_test)
# Affichage des r√©sultats de la pr√©diction
plt.scatter(y_pred_test, y_test)
plt.plot((y_test.min(), y_test.max()), (y_test.min(), y_test.max()), "r")
plt.show()

# pr√©diction √† partir de l'environnement train
y_pred_train = slr.predict(X_train)
# R√©sidus sur l'environnement train
residus = y_pred_train - y_train
display(residus.describe())

# nuage des r√©sidus
plt.scatter(y_train, residus, color="#980a10", s=15)
# ligne horizontale √† 0
plt.axhline(y=0, color="blue", linestyle="--")
# OU plt.plot((y_train.min(), y_train.max()), (0, 0), lw=3, color='#0a5798')
plt.xlabel("Valeurs pr√©dites depuis l'environnement train")
plt.ylabel("R√©sidus")
plt.title("Plot des r√©sidus vs valeurs pr√©dites (environnement train)")
plt.show()


# Normalit√© des r√©sidus
import scipy.stats as stats

residus_norm = (residus - residus.mean()) / residus.std()
stats.probplot(residus_norm, plot=plt)
plt.show()

# Selection des colonnes pour la matrice de corr√©lation et le pairplot
cols = [
    "wheelbase",
    "carlength",
    "carwidth",
    "carheight",
    "curb-weight",
    "enginesize",
    "boreratio",
    "stroke",
    "compressionratio",
    "horsepower",
    "peakrpm",
    "citympg",
    "highwaympg",
    "price",
]
# Matrice de corr√©lation
# plt.figure(figsize=(16, 15))
# sns.heatmap(df[cols].corr(), annot=True, cmap="RdBu_r", center=0)
# plt.show()

# Pairplot pour visualiser les relations entre certaines variables
# sns.pairplot(data=df[['curb-weight', 'horsepower', 'highway-mpg', 'height', 'bore', 'width','price']])
# sns.pairplot(data=df[cols])
# plt.show()


# Pour v√©rification # signif_features = ['curb-weight', 'horsepower', 'boreratio', 'carwidth', 'price']
# Matrice de corr√©lation
# plt.figure(figsize=(16, 15))
# sns.heatmap(df[signif_features].corr(), annot=True, cmap="RdBu_r", center=0)
# plt.show()

# # Pairplot pour visualiser les relations entre certaines variables
# # sns.pairplot(data=df[['curb-weight', 'horsepower', 'highway-mpg', 'height', 'bore', 'width','price']])
# sns.pairplot(data=df[signif_features])
# plt.show()

# S√©lection des caract√©ristiques significatives
signif_features = ['curb-weight', 'horsepower', 'boreratio', 'carwidth']

# Etape 2 --> Affinage du modele de regression multiple
# Entra√Ænement du mod√®le avec les caract√©ristiques significatives
lr2 = LinearRegression()
lr2.fit(X_train[signif_features], y_train)

# Score (R¬≤) sur l'entra√Ænement
print('Score (R¬≤) sur train :', lr2.score(X_train[signif_features], y_train))
# Score (R¬≤) sur le test
print('Score (R¬≤) sur test  :', lr2.score(X_test[signif_features], y_test))

# S√©lection des meilleures caract√©ristiques avec SelectKBest
from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import f_regression

# Instancier SelectKBest avec f_regression
sk = SelectKBest(f_regression, k=4)
sk.fit(X_train, y_train)
display(X.columns[sk.get_support()])

# Transformation des donn√©es d'entra√Ænement et de test
sk_train = sk.transform(X_train)
sk_test = sk.transform(X_test)

# Entra√Ænement du mod√®le avec les donn√©es transform√©es
sklr = LinearRegression()
sklr.fit(sk_train, y_train)

print('Score (R¬≤) sur train optimis√© via SelectKBest:', sklr.score(sk_train, y_train))
print('Score (R¬≤) sur test optimis√© via SelectKBest :', sklr.score(sk_test, y_test))


# Utilisation de SelectFromModel pour la s√©lection de caract√©ristiques
from sklearn.feature_selection import SelectFromModel

# Regression Lin√©aire
lr4 = LinearRegression()

# Selection des meilleures colonnes par poids de pr√©diction
sfm = SelectFromModel(lr4)

# standardisation des donn√©es
scaler = preprocessing.StandardScaler().fit(X_train)

# format tableau (si dataframe --> pd.DataFrame()...)
X_train_scaled = scaler.transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Entrainement sur les donn√©es standardis√©es et sauvegarde des donn√©es transform√©es
sfm_train = sfm.fit_transform(X_train_scaled, y_train)
sfm_test = sfm.transform(X_test_scaled)

# Affichage des colonnes s√©lectionn√©es par SelectFromModel
display(X.columns[sfm.get_support()])

# Cr√©er un mod√®le √† partir des donn√©es sauvegard√©es
lr5 = LinearRegression()
lr5.fit(sfm_train, y_train)

# affichez le score du mod√®le sur les √©chantillons d'entra√Ænement et de test
print('Score (R¬≤) sur train normalis√© et optimis√© via SelectFromModel :', lr5.score(sfm_train, y_train))
print('Score (R¬≤) sur test normalis√© et optimis√© via SelectFromModel  :', lr5.score(sfm_test, y_test))
